<!DOCTYPE HTML>
<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Manuel Lagunas</title>

  <meta name="author" content="Jon Barron">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon"
    href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>🌐</text></svg>">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
</head>
</head>

<body>
  <table
    style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">


            <tbody>
              <tr style="padding:0px">
                <td style="padding:2.5%;width:63%;vertical-align:middle">
                  <p style="text-align:center">
                    <name>Manuel Lagunas</name>
                  </p>
                  <p class="justify">I am an applied scientist at <a href="https://www.amazon.science/">Amazon</a> in
                    Madrid, where I
                    work on developing computer vision and machine learning techniques to solve catalog issues.
                    Before, I did my PhD at <a href="https://www.unizar.es/">Universidad de Zaragoza</a>, where I was
                    advised by <a href="http://giga.cps.unizar.es/~diegog/">Diego Gutierrez</a> and <a
                      href="http://webdiis.unizar.es/~bmasia/">Belen Masia</a>. During my PhD, I was working on problems
                    at the interface between computer vision, computer graphics, and human perception.
                    <br>
                    <br>
                    You can contact me at <strong>mlgns at amazon dot com</strong>
                  </p>


                  <p style="text-align:center">
                    <a href="data/mlagunas_cv.pdf"><i class="fa fa-file-text" style="font-size:13px"></i></a>
                    &nbsp·&nbsp
                    <!-- <a href="mailto:jonbarron@gmail.com"><i class="fa fa-envelope" ></i></a> &nbsp·&nbsp -->
                    <!-- <a href="data/JonBarron-bio.txt">Bio</a> &nbsp/&nbsp -->
                    <a href="https://scholar.google.com/citations?user=KmsA_NYAAAAJ&hl=en"><i
                        class="fa fa-graduation-cap"></i></a>
                    &nbsp·&nbsp
                    <a href="https://twitter.com/mlagunas_"><i class="fa fa-twitter" style="font-size:16px"></i></a>
                    &nbsp·&nbsp
                    <a href="https://github.com/mlagunas"><i class="fa fa-github" style="font-size:17px"></i> </i></a>
                    &nbsp·&nbsp
                    <a href="https://www.linkedin.com/in/mlagunas/"><i class="fa fa-linkedin"
                        style="font-size:17px"></i> </i></a>
                  </p>
                </td>
                <td style="padding:2.5%;width:40%;max-width:40%;margin-top: auto;">
                  <a href="images/profile_photo.png"><img style="width:100%;max-width:100%;border-radius: 10%;"
                      alt="profile photo" src="images/profile_photo.png" class="hoverZoomLink"></a>
                </td>
              </tr>
            </tbody>
          </table>

          <hr>

          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <heading>Publications</heading>
                  <p class="justify">
                    I am interested in topics at the interface between computer vision and computer graphics. Those
                    include - but are not limited to - how can we inversely model the world i.e. acquire material
                    properties, light, or geometry from simple input sources (images); or how can we develop faster/
                    more intuitive methods to manipulate digital assets or foster artistic processes.
                  </p>
                </td>
              </tr>
            </tbody>
          </table>

          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>



              <tr onmouseout="editing_stop()" onmouseover="editing_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='editing_image' style="border-radius: 2%;overflow: hidden;z-index: 1;" ß><video
                        width=100% height=100% muted autoplay loop>
                        <source src="videos/2023_cgf_editing.mp4" type="video/mp4" style="border-radius: 2%;">
                        Your browser does not support the video tag.
                      </video></div>
                    <img id='editing_bg' src='images/2023_cgf_editing.png' width="160" style="border-radius: 2%;">
                  </div>

                  <script type="text/javascript">
                    function editing_start() {
                      document.getElementById('editing_image').style.opacity = "1";
                      document.getElementById('editing_bg').style.opacity = "0";
                    }

                    function editing_stop() {
                      document.getElementById('editing_bg').style.opacity = "1";
                      document.getElementById('editing_image').style.opacity = "0";

                    }

                    editing_stop()
                  </script>
                </td>

                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://arxiv.org/abs/2302.03619">
                    <papertitle>In-the-wild Material Appearance Editing using Perceptual Attributes</papertitle>
                  </a>
                  <br>
                  J. Daniel Subias, <b>Manuel Lagunas</b>
                  <br>
                  <em>Computer Graphics Forum (CGF, proc. Eurographics)</em>, 2023</strong></font>
                  <br>
                  <a href="https://arxiv.org/abs/2302.03619">arXiv</a>
                  <!-- ·
                  <a href="">Code (TBD)</a>
                  ·
                  <a href="">Bib (TBD)</a> -->
                  <p></p>

                  <p><i>
                      We perform in-the-wild intuitive material editing using perceptual attributes. We recover high
                      frequency details from the input while mantaining the intuitive editing capacity of the model.
                    </i>
                  </p>
                </td>
              </tr>

              <!-- ************************* -->

              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <img src='images/2022_cgf_editing.png' width="160" style="border-radius: 2%;">
                  </div>

                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://perso.liris.cnrs.fr/johanna.delanoy/2022_materials_generative_editing/index.html">
                    <papertitle>A Generative Framework for Image‐based Editing of Material Appearance using Perceptual
                      Attributes</papertitle>
                  </a>
                  <br>
                  Johanna Delanoy, <b>Manuel Lagunas</b>, Jorge Condor, Diego Gutierrez, Belen Masia
                  <br>
                  <em>Computer Graphics Forum (CGF)</em>, 2022</strong></font>
                  <br>
                  <a href="https://perso.liris.cnrs.fr/johanna.delanoy/2022_materials_generative_editing/index.html">Project
                    page</a>
                  ·
                  <a href="https://arxiv.org/abs/2107.07259">arXiv</a>
                  ·
                  <a href="https://github.com/jdelanoy/generative-material-net">Code</a>
                  ·
                  <a href="bibs/2022_cgf_editing.html">Bib</a>
                  <p></p>

                  <p><i>
                      We rely on an estimation of the
                      geometry from the input image and an editing network that uses high-level perceptual attributes to
                      perform intuitive material editing. </i>
                  </p>
                </td>
              </tr>

              <!-- ************************* -->

              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <img src='images/2021_tesis.png' width="160" style="border-radius: 2%;">
                  </div>

                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://zaguan.unizar.es/record/110888/files/TESIS-2022-057.pdf">
                    <papertitle>Learning Visual Appearance: Percetion, Modeling and Editing</papertitle>
                  </a>
                  <br>
                  <b>Manuel Lagunas</b>
                  <br>
                  <em>supervised by Diego Gutierrez and Belen Masia</em>, 2021</strong></font>
                  <br>
                  Cum Laude (highest grade awarded by the institution where the PhD was defended) 
                  <br>
                  <a href="https://zaguan.unizar.es/record/110888/files/TESIS-2022-057.pdf">Pdf</a>

                  <p></p>

                  <p><i>
                    This thesis improves visual content creation algorithms by connecting physical parameters to intuitive human attributes related to visual appearance.</i>
                  </p>
                </td>
              </tr>

              <!-- ************************* -->

              <tr onmouseout="relighting_stop()" onmouseover="relighting_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='relighting_image' style="border-radius: 2%;overflow: hidden;z-index: 1;"><video
                        width=100% height=100% muted autoplay loop>
                        <source src="videos/2021_egsr_relighting.mp4" type="video/mp4" style="border-radius: 2%;">
                        Your browser does not support the video tag.
                      </video></div>
                    <img src='images/2021_egsr_relighting.png' width="160" style="border-radius: 2%;">
                  </div>

                  <script type="text/javascript">
                    function relighting_start() {
                      document.getElementById('relighting_image').style.opacity = "1";
                    }

                    function relighting_stop() {
                      document.getElementById('relighting_image').style.opacity = "0";
                    }

                    relighting_stop()
                  </script>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://dreamfusion3d.github.io/">
                    <papertitle>Single-image Full-body Human Relighting</papertitle>
                  </a>
                  <br>
                  <b>Manuel Lagunas</b>, Xin Sun, Jimei Yang, Ruben Villegas, Jianming Zhang, Zhixin Shu, Belen Masia,
                  Diego Gutierrez
                  <br>
                  <em>Eurographics Symposium on Rendering (Proc. EGSR)</em>, 2021</strong></font>
                  <br>
                  <a href="https://arxiv.org/abs/2107.07259">arXiv</a>
                  ·
                  <a href="https://github.com/mlagunas/full_body-human_relighting">Code</a>
                  ·
                  <a href="bibs/2021_egsr_relighting.html">Bib</a>
                  <p></p>

                  <p><i>
                      We train a generative model to perform in-the-wild human relighting lifting the assumptions on
                      materials being Lambertian. </i>
                  </p>
                </td>
              </tr>


              <!-- ************************* -->

              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <img src='images/2021_jov_perception.png' width="160" style="border-radius: 2%;">
                  </div>

                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://jov.arvojournals.org/article.aspx?articleid=2772241">
                    <papertitle>The Joint Role of Geometry and Illumination on Material Recognition</papertitle>
                  </a>
                  <br>
                  <b>Manuel Lagunas</b>, Ana Serrano, Diego Gutierrez, Belen Masia
                  <br>
                  <em>Journal of Vision (JoV)</em>, 2021</strong></font>
                  <br>
                  <a href="https://jov.arvojournals.org/article.aspx?articleid=2772241">Project page</a>
                  ·
                  <a href="https://arxiv.org/abs/2101.02496">arXiv</a>
                  ·
                  <a href="bibs/2021_jov_perception.html">Bib</a>

                  <p></p>

                  <p><i>
                      Comprehensive study on the influence of geometry, illumination, and their frequencies in our
                      performance recognizing materials from images. </i>
                  </p>
                </td>
              </tr>

              <!-- ************************* -->

              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <img src='images/2020_togP_similarity.png' width="160" style="border-radius: 2%;">
                  </div>

                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://dl.acm.org/doi/10.1145/3388770.3407444">
                    <papertitle>The Role of Objective and Subjective Measures in Material Similarity Learning
                    </papertitle>
                  </a>
                  <br>
                  Johana Delanoy, <b>Manuel Lagunas</b>, Ignacion Galve, Diego Gutierrez, Ana Serrano, Roland Fleming,
                  Belen Masia

                  <br>
                  <em>ACM Transactions on Graphics Posters</em>, 2020</strong></font>
                  <br>
                  <a href="https://graphics.unizar.es/papers/2020_networks_material_abstract.pdf">Abstract</a>
                  ·
                  <a href="https://graphics.unizar.es/papers/2020_networks_material_poster.pdf">Poster</a>
                  <p></p>

                  <p><i>
                      Analysis of subjective and objective measures when we develop computational methods for material
                      similarity.</i>
                  </p>
                </td>
              </tr>


              <!-- ************************* -->

              <tr onmouseout="similarity_stop()" onmouseover="similarity_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div classß="one">
                    <div class="two" id='similarity_image' style="border-radius: 2%;overflow: hidden;z-index: 1;"><video
                        width=100% height=100% muted autoplay loop>
                        <source src="videos/2019_tog_similarity.mp4" type="video/mp4" style="border-radius: 2%;">
                        Your browser does not support the video tag.
                      </video></div>
                    <img src='images/2019_tog_similarity.png' width="160" style="border-radius: 2%;">
                  </div>

                  <script type="text/javascript">
                    function similarity_start() {
                      document.getElementById('similarity_image').style.opacity = "1";
                    }

                    function similarity_stop() {
                      document.getElementById('similarity_image').style.opacity = "0";
                    }

                    similarity_stop()
                  </script>
                </td>

        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="http://webdiis.unizar.es/~mlagunas/publication/material-similarity/">
            <papertitle>A Similarity Measure for Material Appearance
            </papertitle>
          </a>
          <br>
          <b>Manuel Lagunas</b>, Sandra Malpica, Ana Serrano, Elena Garces, Diego Gutierrez, Belen Masia


          <br>
          <em>ACM Transactions on Graphics (TOG, Proc. SIGGRAPH)</em>, 2019</strong></font>
          <br>
          <a href="http://webdiis.unizar.es/~mlagunas/publication/material-similarity/">Project page</a>
          ·
          <a href="https://arxiv.org/abs/1905.01562">Arxiv</a>
          ·
          <a href="https://github.com/mlagunas/material-appearance-similarity">Code</a>
          ·
          <a href="bibs/2019_tog_similarity.html">Bib</a>
          <p></p>

          <p><i>
              We introduce a neural-based similarity metric that learns from perceptual data. It
              outperforms state of the art, is aligned with human perception, and
              can be used for several applications.</i>
          </p>
        </td>
      </tr>

      <!-- ************************* -->

      <tr>
        <td style="padding:20px;width:25%;vertical-align:middle">
          <div class="one">
            <img src='images/2019_sap_motion.png' width="160" style="border-radius: 2%;">
          </div>

        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="https://dl.acm.org/doi/10.1145/3343036.3343122">
            <papertitle>The Effect of Motion on the Perception of Material Appearance
            </papertitle>
          </a>
          <br>
          Ruiquan Mao, <b>Manuel Lagunas</b>, Belen Masia, Diego Gutierrez


          <br>
          <em>ACM Symposium on Applied Perception (SAP)</em>, 2019</strong></font>
          <br>
          <a href="https://graphics.unizar.es/docs/Mao_2019_EffectMotion.pdf">Pdf</a>
          ·
          <a href="bibs/2019_sap_motion.html">Bib</a>
          <p></p>

          <p><i>
              Comprehensive study of the effect of motion in our perception of high-level perceptual attributes that
              describe material appearance.</i>
          </p>
        </td>
      </tr>

      <!-- ************************* -->

      <tr>
        <td style="padding:20px;width:25%;vertical-align:middle">
          <div class="one">
            <img src='images/2018_mtap_icons.png' width="160" style="border-radius: 2%;">
          </div>

        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="https://link.springer.com/article/10.1007/s11042-018-6628-7">
            <papertitle>Learning Icons Appearance Similarity
            </papertitle>
          </a>
          <br>
          <b>Manuel Lagunas</b>, Elena Garces, Diego Gutierrez



          <br>
          <em>Multimedia Tools and Applications (MTAP)</em>, 2018</strong></font>
          <br>
          <a href="https://arxiv.org/abs/1902.05378">Arxiv</a>
          ·
          <a href="bibs/2018_mtap_icons.html">Bib</a>
          <p></p>

          <p><i>
              We introduce a similarity model capable of retrieving icons based on their style and visual identity. We
              rely on a siamese model paired with a triplet loss function that learns from crowd-sourced data.</i>
          </p>
        </td>
      </tr>

      <!-- ************************* -->

      <tr>
        <td style="padding:20px;width:25%;vertical-align:middle">
          <div class="one">
            <img src='images/2017_ceig_illustration.png' width="160" style="border-radius: 2%;">
          </div>

        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="https://arxiv.org/abs/1806.02682">
            <papertitle>Transfer Learning for Illustration Classification
            </papertitle>
          </a>
          <br>
          <b>Manuel Lagunas</b>, Elena Garces
          <br>
          <em>Conferencia Española de Informatica Grafica (Proc. CEIG)</em>, 2017</strong></font>
          <br>
          <a href="https://arxiv.org/abs/1806.02682">Arxiv</a>
          ·
          <a href="https://github.com/mlagunas/DLart">Code</a>
          ·
          <a href="bibs/2017_ceig_illustration.html">Bib</a>
          <p></p>

          <p><i>
              We develop a transfer learning method that fine tunes the initial layers of a convolutional neural
              network. This allows it to learn low-level features (strokes) wich are important in illustrations.</i>
          </p>
        </td>
      </tr>

    </tbody>
  </table>

  <hr>

  <!-- ********************************************************* -->

  <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
    <tbody>
      <tr>
        <td>
          <heading></heading>
        </td>
      </tr>
    </tbody>
  </table>
  <!-- <table width="100%" align="center" border="0" cellpadding="20">
    <tbody>

      <tr>
        <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/cvf.jpg"></td>
        <td width="75%" valign="center">
          <a href="https://cvpr2022.thecvf.com/area-chairs">Area Chair, CVPR 2022</a>
          <br>
          <a href="http://cvpr2021.thecvf.com/area-chairs">Area Chair & Longuet-Higgins Award Committee Member,
            CVPR 2021</a>
          <br>
          <a href="http://cvpr2019.thecvf.com/area_chairs">Area Chair, CVPR 2019</a>
          <br>
          <a href="http://cvpr2018.thecvf.com/organizers/area_chairs">Area Chair, CVPR 2018</a>
        </td>
      </tr>
      <tr>
        <td style="padding:20px;width:25%;vertical-align:middle">
          <img src="images/cs188.jpg" alt="cs188">
        </td>
        <td width="75%" valign="center">
          <a href="http://inst.eecs.berkeley.edu/~cs188/sp11/announcements.html">Graduate Student Instructor,
            CS188 Spring 2011</a>
          <br>
          <a href="http://inst.eecs.berkeley.edu/~cs188/fa10/announcements.html">Graduate Student Instructor,
            CS188 Fall 2010</a>
          <br>
          <a href="http://aima.cs.berkeley.edu/">Figures, "Artificial Intelligence: A Modern Approach", 3rd
            Edition</a>
        </td>
      </tr>


      <tr>
        <td align="center" style="padding:20px;width:25%;vertical-align:middle">
          <heading>Basically <br> Blog Posts</heading>
        </td>
        <td width="75%" valign="middle">
          <a href="https://arxiv.org/abs/2112.11687">Squareplus: A Softplus-Like Algebraic Rectifier</a>
          <br>
          <a href="https://arxiv.org/abs/2010.09714">A Convenient Generalization of Schlick's Bias and Gain
            Functions</a>
          <br>
          <a href="https://arxiv.org/abs/1704.07483">Continuously Differentiable Exponential Linear Units</a>
        </td>
      </tr>


    </tbody>
  </table> -->
  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr>
        <td style="padding:0px">
          <br>
          <p style="text-align:right;font-size:small;">
            Feel free to steal this website's <a href="https://github.com/jonbarron/jonbarron_website">source
              code</a>. <strong>Do not</strong> scrape the HTML from this page itself, as it includes analytics
            tags that you do not want on your own website &mdash; use the github code instead. Also, consider
            using <a href="https://leonidk.com/">Leonid Keselman</a>'s <a
              href="https://github.com/leonidk/new_website">Jekyll fork</a> of this page.
          </p>
        </td>
      </tr>
    </tbody>
  </table>
  </td>
  </tr>
  </table>
</body>

</html>